# Basic GAN on MNIST

Generative Adversarial Networks(GANs) represent a milestone in the history of image generation. In this project, I developed a basic Generative Adversarial Network(GAN) to generate images based on the MNIST dataset(a collection of handwritten digits).

#### Table of contents

1. **Introduction to GAN**
2. **Model Architecture and Training Logic**
3. **Project Structure**
4. **How to Run**

## 1. Introduction to GAN

A Generative Adversarial Network, first introduced by Ian Goodfellow et al. in 2014, is a class of machine learning frameworks where two neural networks contest with each other in a zero-sum game.

The two networks are:

1. **The Generator ($G$)**: Its goal is to create data that is indistinguishable from real data. It takes a random noise vector ($z$) as input and outputs a synthetic sample, for instance, an image $G(z)$.
2. **The Discriminator ($D$)**: Its goal is to distinguish between real data ($x$) and fake data generated by the Generator. It takes a sample as input and outputs a single scalar value representing the probability that the sample is real.

The training process can be analogized to a game between a counterfeiter (the Generator) and a police detective (the Discriminator). The counterfeiter learns to produce increasingly realistic fake currency, while the detective gets better at telling real currency from fake. This competition drives both to improve until the counterfeiter's fakes are virtually indistinguishable from the real thing.

Mathematically, this adversarial process is represented by a min-max objective function:

$$ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] $$

Where:

- $G$ is the Generator and $D$ is the Discriminator.
- $p_{data}(x)$ is the distribution of the real data.
- $p_z(z)$ is the distribution of the input noise.
- $D(x)$ is the probability that the Discriminator thinks $x$ is real.
- $G(z)$ is the Generator's output (a fake sample).
- $D(G(z))$ is the probability that the Discriminator thinks the fake sample is real.

The Discriminator $D$ tries to maximize this function, making $D(x)$ close to 1 (for real data) and $D(G(z))$ close to 0 (for fake data). The Generator $G$ tries to minimize it by making $D(G(z))$ close to 1, effectively fooling the Discriminator.

## 2. Model Architecture and Training Logic

Instead of using Multi-Layer Perceptrons (MLPs) Architecture, this project employs a convolutional architecture, similar to a simplified Deep Convolutional GAN (DCGAN), which is more effective for image tasks than simple Multi-Layer Perceptrons.(Actually, simple MLPs seems very poor in this work. I tried many times but mode collapse happened in each attempt)

#### Generator ($G$)

The Generator upsamples a latent vector into a 28x28 grayscale image. It uses Transposed Convolution layers (`ConvTranspose2d`) to increase the spatial dimensions of the feature maps.

- **Input**: A 100-dimensional latent vector (random noise).
- **Output**: A 28x28x1 image with pixel values scaled between 0 and 1.

| Layer Type                | Output Shape               | Activation |
| :------------------------ | :------------------------- | :--------- |
| **Input (Latent Vector)** | `(batch_size, 100)`        | -          |
| Linear                    | `(batch_size, 3136)`       | -          |
| *Reshape*                 | `(batch_size, 64, 7, 7)`   | -          |
| ConvTranspose2d           | `(batch_size, 32, 14, 14)` | ReLU       |
| ConvTranspose2d           | `(batch_size, 1, 28, 28)`  | Sigmoid    |
| **Output (Image)**        | `(batch_size, 1, 28, 28)`  | -          |

#### Discriminator ($D$)

The Discriminator is a standard Convolutional Neural Network (CNN) that takes an image and downsamples it to produce a single probability score indicating if the image is real or fake.

- **Input**: A 28x28x1 image.
- **Output**: A single scalar probability (0 for fake, 1 for real).

| Layer Type               | Output Shape               | Activation      |
| :----------------------- | :------------------------- | :-------------- |
| **Input (Image)**        | `(batch_size, 1, 28, 28)`  | -               |
| Conv2d                   | `(batch_size, 16, 14, 14)` | LeakyReLU (0.2) |
| Conv2d                   | `(batch_size, 32, 7, 7)`   | LeakyReLU (0.2) |
| *Flatten*                | `(batch_size, 1568)`       | -               |
| Linear                   | `(batch_size, 1)`          | Sigmoid         |
| **Output (Probability)** | `(batch_size, 1)`          | -               |

#### Training Logic

The training proceeds in alternating steps for a fixed number of epochs:

1. **Train the Discriminator**:
   - A batch of real images is sampled from the MNIST dataset. The Discriminator is trained to classify them as real (target label = 1).
   - A batch of fake images is created by passing random noise through the Generator. The Discriminator is trained to classify these as fake (target label = 0).
   - The losses from both real and fake batches are combined, and the Discriminator's weights are updated via backpropagation.
2. **Train the Generator**:
   - A new batch of fake images is generated.
   - These images are passed to the Discriminator.
   - The Generator's loss is calculated based on how well it fooled the Discriminator. The Generator's goal is for the Discriminator to classify its fake images as real (target label = 1).
   - **Crucially**, during this step, only the Generator's weights are updated. The Discriminator's weights are frozen.

This two-step process is repeated, allowing both networks to improve in tandem.

## 3.Project Structure

```
.
├── src/                  # Source code
│   ├── models.py         # Generator and Discriminator classes
│   ├── trainer.py        # Trainer class with the training loop
│   ├── utils/            # Helper functions (e.g., logger)
│   │   ├──logger.py      # Setup logger
│   └── main.py           # Main script to run the training
├── results/              # Output folder for generated images
├── config.yaml           # All hyperparameters and paths
├── requirements.txt      # Python dependencies
└── README.md             # This file
```

## 4.How to Run

**1. Create a Virtual Environment (Recommended) **

```bash
# For Linux/macOS
python3 -m venv venv
source venv/bin/activate

# For Windows
python -m venv venv
venv\Scripts\activate
```

**2. Install Dependencies**

```bash
pip install -r requirements.txt
```

**3. Start Training** 

Run the main training script. The script will automatically download the MNIST dataset into the `data/` directory.

```bash
python main.py
```

**4. Check the Results**

During training, sample images generated by the GAN will be saved periodically to the `result/fake_images/` directory. You can monitor this folder to see how the Generator improves over time.